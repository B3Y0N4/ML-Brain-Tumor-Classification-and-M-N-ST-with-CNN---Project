{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpx1UXNsdqVLAgAooD6i6a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"GV2lQAPO3oPg","executionInfo":{"status":"error","timestamp":1677853941099,"user_tz":-180,"elapsed":396,"user":{"displayName":"Jalal Jr","userId":"08481911706047051466"}},"outputId":"a796ab9c-d909-4764-8f0e-82e08de2e60d"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c9ef45beb805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'img_to_array' from 'keras.preprocessing.image' (/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","from keras.preprocessing.image import img_to_array, array_to_img\n","import numpy as np\n","\n","\n","# MNIST veri setini yükle\n","(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n","\n","# Resize images to match input shape of model\n","train_images_resized = np.array([img_to_array(array_to_img(im, scale=False).resize((227,227))) for im in train_images])\n","test_images_resized = np.array([img_to_array(array_to_img(im, scale=False).resize((227,227))) for im in test_images])\n","\n","# Normalize pixel values\n","train_images_resized = train_images_resized.astype('float32') / 255\n","test_images_resized = test_images_resized.astype('float32') / 255\n","\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(filters=96, kernel_size=(11, 11), \n","                        strides=(4, 4), activation=\"relu\", \n","                        input_shape=(227, 227, 3)))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n","model.add(layers.Conv2D(filters=256, kernel_size=(5, 5), \n","                        strides=(1, 1), activation=\"relu\", \n","                        padding=\"same\"))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n","model.add(layers.Conv2D(filters=384, kernel_size=(3, 3), \n","                        strides=(1, 1), activation=\"relu\", \n","                        padding=\"same\"))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Conv2D(filters=384, kernel_size=(3, 3), \n","                        strides=(1, 1), activation=\"relu\", \n","                        padding=\"same\"))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), \n","                        strides=(1, 1), activation=\"relu\", \n","                        padding=\"same\"))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(4096, activation=\"relu\"))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation=\"softmax\"))\n","\n","\n","model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              optimizer='adam', \n","              metrics=['accuracy'])\n","\n","\n","# Modeli eğit\n","history = model.fit(train_images, train_labels, epochs=5,\n","                    validation_data=(test_images, test_labels))\n","\n","# Modelin performansını değerlendir\n","test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print('\\nTest accuracy:', test_acc)"]}]}